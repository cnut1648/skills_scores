{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = config.LINKEDIN_URL\n",
    "batch_of_25 = config.BATCH_OF_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will open up new window with the url provided above \n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located(\n",
    "        (By.XPATH, \"/html/body/main/div/section/button\")\n",
    "    )\n",
    ")\n",
    "action = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i < batch_of_25:\n",
    "    # scroll to botton to load next 25 jobs\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i += 1\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are scraping information about 75 jobs.\n"
     ]
    }
   ],
   "source": [
    "# parsing the visible wZebpage\n",
    "pageSource = driver.page_source\n",
    "lxml_soup = BeautifulSoup(pageSource, 'lxml')\n",
    "\n",
    "# searching for all job containers\n",
    "job_container = lxml_soup.find('ul', class_ = 'jobs-search__results-list')\n",
    "\n",
    "total_jobs = len(job_container)\n",
    "print(f'You are scraping information about {total_jobs} jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 1/75\n",
      "downloading 2/75\n",
      "downloading 3/75\n",
      "downloading 4/75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2a24d1d54363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mjob_xpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/html/body/main/div/section/ul/li[{}]/img'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_xpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# job description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setting up list for job information\n",
    "job_id = []\n",
    "post_title = []\n",
    "company_name = []\n",
    "post_date = []\n",
    "job_location = []\n",
    "job_desc = []\n",
    "level = []\n",
    "emp_type = []\n",
    "functions = []\n",
    "industries = []\n",
    "\n",
    "# for loop for job title, company, id, location and date posted\n",
    "for job in job_container:\n",
    "    # job title\n",
    "    job_titles = job.find(\"span\", class_=\"screen-reader-text\").text\n",
    "    post_title.append(job_titles)\n",
    "    \n",
    "    # linkedin job id\n",
    "    job_ids = job.find('a', href=True)['href']\n",
    "    job_ids = re.findall(r'(?!-)([0-9]*)(?=\\?)',job_ids)[0]\n",
    "    job_id.append(job_ids)\n",
    "    \n",
    "    # company name\n",
    "    company_names = job.select_one('img')['alt']\n",
    "    company_name.append(company_names)\n",
    "    \n",
    "    # job location\n",
    "    job_locations = job.find(\"span\", class_=\"job-result-card__location\").text\n",
    "    job_location.append(job_locations)\n",
    "    \n",
    "    # posting date\n",
    "    post_dates = job.select_one('time')['datetime']\n",
    "    post_date.append(post_dates)\n",
    "\n",
    "# for loop for job description and criterias\n",
    "for x in range(1,len(job_id)+1):\n",
    "    print(f\"downloading {x}/{total_jobs}\", end = \"\\r\")\n",
    "    \n",
    "    # clicking on different job containers to view information about the job\n",
    "    job_xpath = '/html/body/main/div/section/ul/li[{}]/img'.format(x)\n",
    "    driver.find_element_by_xpath(job_xpath).click()\n",
    "    sleep(3)\n",
    "    \n",
    "    # job description\n",
    "    jobdesc_xpath = '/html/body/main/section/div[2]/section[2]/div'\n",
    "    job_descs = driver.find_element_by_xpath(jobdesc_xpath).text\n",
    "    job_desc.append(job_descs)\n",
    "    \n",
    "    # job criteria container below the description\n",
    "    job_criteria_container = lxml_soup.find('ul', class_ = 'job-criteria__list')\n",
    "    all_job_criterias = job_criteria_container.find_all(\"span\", class_='job-criteria__text job-criteria__text--criteria')\n",
    "    \n",
    "    # Seniority level\n",
    "    seniority_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[1]'\n",
    "    seniority = driver.find_element_by_xpath(seniority_xpath).text.splitlines(0)[1]\n",
    "    level.append(seniority)\n",
    "    \n",
    "    # Employment type\n",
    "    type_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[2]'\n",
    "    employment_type = driver.find_element_by_xpath(type_xpath).text.splitlines(0)[1]\n",
    "    emp_type.append(employment_type)\n",
    "    \n",
    "    # Job function\n",
    "    function_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[3]'\n",
    "    job_function = driver.find_element_by_xpath(function_xpath).text.splitlines(0)[1]\n",
    "    functions.append(job_function)\n",
    "    \n",
    "    # Industries\n",
    "    industry_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[4]'\n",
    "    industry_type = driver.find_element_by_xpath(industry_xpath).text.splitlines(0)[1]\n",
    "    industries.append(industry_type)\n",
    "    \n",
    "    x = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "job_data = pd.DataFrame({'Job ID': job_id,\n",
    "'Date': post_date,\n",
    "'Company Name': company_name,\n",
    "'Post': post_title,\n",
    "'Location': job_location,\n",
    "'Description': job_desc,\n",
    "'Level': level,\n",
    "'Type': emp_type,\n",
    "'Function': functions,\n",
    "'Industry': industries\n",
    "})\n",
    "\n",
    "# cleaning description column\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n',' ')\n",
    "job_data[\"Description\"] = job_data['Description'].str.replace('Show more', \"\")\n",
    "\n",
    "print(job_data.info())\n",
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.to_csv(f\"{date.today()}-linkein.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
